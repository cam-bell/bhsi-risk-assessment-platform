"""
RAG Natural Language Analysis Endpoint

ğŸš€ NEW FEATURE: Natural Language Risk Analysis using RAG
ğŸ“ ADDITIVE: This file is completely new and separate from existing endpoints
ğŸ”„ LEVERAGES: Existing cloud services (Vector Search + Gemini) + BigQuery vectors
âš ï¸ REMOVABLE: Can be deleted without affecting existing functionality

Usage: POST /api/v1/analysis/nlp/ask
Example: "What are the current risks for Banco Santander?"
"""

import logging
import asyncio
from typing import List, Optional, Dict, Any
from datetime import datetime
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field
import httpx
import os

# ğŸ”’ SAFE IMPORT: Only using auth from existing system
from app.dependencies.auth import get_current_active_user

# ğŸ”— NEW IMPORT: Use BigQuery vector store for accurate searches
from app.services.vector_search.bigquery_vector_store import VectorSearchService
from sentence_transformers import SentenceTransformer

logger = logging.getLogger(__name__)

# ğŸ“ NEW ROUTER: Completely separate from existing routers
router = APIRouter()

# ğŸŒ CLOUD SERVICES: Using existing deployed services
VECTOR_SEARCH_URL = os.getenv("VECTOR_SEARCH_SERVICE_URL", "https://vector-search-185303190462.europe-west1.run.app")
GEMINI_SERVICE_URL = os.getenv("GEMINI_SERVICE_URL", "https://gemini-service-185303190462.europe-west1.run.app")

# ğŸ“‹ NEW MODELS: RAG-specific request/response models
class RAGQueryRequest(BaseModel):
    question: str = Field(..., description="Natural language question about corporate risks", min_length=10)
    max_documents: Optional[int] = Field(3, description="Maximum documents to retrieve", ge=1, le=10)
    company_filter: Optional[str] = Field(None, description="Filter by specific company name")
    language: Optional[str] = Field("es", description="Response language (es/en)")

class RAGDocumentSource(BaseModel):
    id: str
    score: float
    title: str
    company: str
    date: str
    source: str
    text_preview: str

class RAGAnalysisResponse(BaseModel):
    question: str
    answer: str
    sources: List[RAGDocumentSource]
    confidence: float
    methodology: str
    response_time_ms: int
    timestamp: str

# ğŸ§  RAG ORCHESTRATOR: Core RAG logic (NEW CLASS)
class RAGOrchestrator:
    """
    ğŸš€ CLOUD-NATIVE RAG: Full integration with deployed microservices
    âœ… Uses: Vector Search Service (BigQuery) + Gemini Service
    """
    
    def __init__(self):
        self.vector_search_url = VECTOR_SEARCH_URL
        self.gemini_service_url = GEMINI_SERVICE_URL
    
    async def analyze_natural_language_query(self, query: RAGQueryRequest) -> RAGAnalysisResponse:
        """Main RAG analysis flow"""
        start_time = datetime.now()
        
        try:
            # Step 1: Retrieve relevant documents
            documents = await self._retrieve_documents(query)
            
            # Step 2: Generate context-aware response
            analysis = await self._generate_analysis(query.question, documents, query.language)
            
            # Step 3: Format response
            response_time = int((datetime.now() - start_time).total_seconds() * 1000)
            
            return RAGAnalysisResponse(
                question=query.question,
                answer=analysis["answer"],
                sources=self._format_sources(documents),
                confidence=analysis["confidence"],
                methodology="rag_vector_gemini",
                response_time_ms=response_time,
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"RAG analysis failed: {str(e)}")
            raise HTTPException(status_code=500, detail=f"RAG analysis failed: {str(e)}")
    
    async def _retrieve_documents(self, query: RAGQueryRequest) -> List[Dict[str, Any]]:
        """ğŸ” STEP 1: Document retrieval using existing vector search service"""
        
        try:
            search_request = {
                "query": query.question,
                "k": query.max_documents
            }
            
            # Add company filter if specified
            if query.company_filter:
                search_request["filter"] = {"company": query.company_filter}
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{self.vector_search_url}/search",
                    json=search_request
                )
                
                if response.status_code == 200:
                    results = response.json()
                    documents = results.get("results", [])
                    logger.info(f"Retrieved {len(documents)} documents for RAG analysis")
                    return documents
                else:
                    logger.error(f"Vector search failed: {response.status_code} - {response.text}")
                    return []
                    
        except Exception as e:
            logger.error(f"Document retrieval failed: {str(e)}")
            return []
    
    async def _generate_analysis(self, question: str, documents: List[Dict[str, Any]], language: str) -> Dict[str, Any]:
        """ğŸ§  STEP 2: Generate analysis using existing Gemini service"""
        
        try:
            # Prepare context from retrieved documents
            context = self._prepare_context(documents)
            
            # Create RAG prompt for Gemini
            prompt = self._create_rag_prompt(question, context, language)
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{self.gemini_service_url}/generate",
                    json={
                        "prompt": prompt,
                        "max_tokens": 800,
                        "temperature": 0.2
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    raw_answer = result.get("text", "No analysis generated")
                    # Remove asterisks and other markdown formatting to make text cleaner
                    clean_answer = self._clean_markdown_formatting(raw_answer)
                    return {
                        "answer": clean_answer,
                        "confidence": self._calculate_confidence(documents)
                    }
                else:
                    logger.error(f"Gemini analysis failed: {response.status_code} - {response.text}")
                    return {
                        "answer": "Lo siento, no pude generar un anÃ¡lisis en este momento debido a un error del servicio.",
                        "confidence": 0.0
                    }
                    
        except Exception as e:
            logger.error(f"Analysis generation failed: {str(e)}")
            return {
                "answer": f"Error en el anÃ¡lisis: {str(e)}",
                "confidence": 0.0
            }
    
    def _prepare_context(self, documents: List[Dict[str, Any]]) -> str:
        """ğŸ“„ Prepare document context for Gemini analysis"""
        
        if not documents:
            return "No se encontraron documentos relevantes."
        
        context_parts = []
        for i, doc in enumerate(documents, 1):
            metadata = doc.get("metadata", {})
            company = metadata.get("company", "Desconocida")
            score = doc.get("score", 0)
            
            context_parts.append(f"""
DOCUMENTO {i} (Relevancia: {score:.2f}, Empresa: {company}):
{doc.get("document", "Sin contenido")}
""")
        
        return "\n".join(context_parts)
    
    def _create_rag_prompt(self, question: str, context: str, language: str) -> str:
        """ğŸ¯ Create specialized RAG prompt for D&O risk analysis"""
        
        language_instructions = {
            "es": "Responde en espaÃ±ol. Proporciona un anÃ¡lisis ejecutivo claro y profesional.",
            "en": "Respond in English. Provide a clear and professional executive analysis."
        }
        
        return f"""
Eres un experto en anÃ¡lisis de riesgos corporativos D&O (Directores y Administradores). Analiza la siguiente pregunta basÃ¡ndote ÃšNICAMENTE en los documentos proporcionados.

PREGUNTA: {question}

DOCUMENTOS DE CONTEXTO:
{context}

INSTRUCCIONES:
1. {language_instructions.get(language, language_instructions["es"])}
2. Basa tu respuesta SOLO en la informaciÃ³n de los documentos
3. Si no hay informaciÃ³n suficiente, dilo claramente
4. Destaca los riesgos clave y su impacto potencial
5. Proporciona informaciÃ³n accionable para ejecutivos
6. MantÃ©n un tono profesional y conciso
7. Menciona las fuentes cuando sea relevante

ANÃLISIS:
"""
    
    def _clean_markdown_formatting(self, text: str) -> str:
        """ğŸ§¹ Remove asterisks and other markdown formatting to make text cleaner and more appealing"""
        
        if not text:
            return text
        
        # Remove bold markdown formatting (**text**)
        import re
        
        # Remove double asterisks (bold formatting)
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        
        # Remove single asterisks (italic formatting) 
        text = re.sub(r'\*([^*]+)\*', r'\1', text)
        
        # Clean up any remaining standalone asterisks
        text = re.sub(r'\*+', '', text)
        
        # Clean up extra whitespace that might result from removing formatting
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)  # Reduce multiple newlines
        text = re.sub(r'^\s+', '', text, flags=re.MULTILINE)  # Remove leading whitespace on lines
        
        return text.strip()
    
    def _calculate_confidence(self, documents: List[Dict[str, Any]]) -> float:
        """ğŸ“Š Calculate confidence based on document relevance scores"""
        
        if not documents:
            return 0.0
        
        total_score = sum(doc.get("score", 0) for doc in documents)
        avg_score = total_score / len(documents)
        
        # Convert to percentage
        confidence = min(avg_score * 100, 100.0)
        return round(confidence, 1)
    
    def _format_sources(self, documents: List[Dict[str, Any]]) -> List[RAGDocumentSource]:
        """ğŸ“‹ Format document sources for response"""
        
        sources = []
        for doc in documents:
            metadata = doc.get("metadata", {})
            
            sources.append(RAGDocumentSource(
                id=doc.get("id", "unknown"),
                score=round(doc.get("score", 0), 2),
                title=metadata.get("titulo", "Sin tÃ­tulo")[:100],
                company=metadata.get("company", "Desconocida"),
                date=metadata.get("fecha", "Fecha desconocida"),
                source=metadata.get("source", "Fuente desconocida"),
                text_preview=doc.get("document", "")[:200] + "..." if len(doc.get("document", "")) > 200 else doc.get("document", "")
            ))
        
        return sources

# ğŸŒ GLOBAL ORCHESTRATOR: Single instance for endpoint
rag_orchestrator = RAGOrchestrator()

# ğŸš€ NEW ENDPOINTS: RAG Natural Language Analysis
@router.post("/nlp/ask", response_model=RAGAnalysisResponse)
async def ask_natural_language_question(
    query: RAGQueryRequest,
    current_user: dict = Depends(get_current_active_user)
):
    """
    ğŸ§  Natural Language Risk Analysis using RAG
    
    Ask questions in natural language about corporate risks and get AI-powered insights.
    
    Examples:
    - "Â¿CuÃ¡les son los riesgos actuales para Banco Santander?"
    - "What financial risks affect Spanish energy companies?"
    - "Â¿Hay algÃºn problema regulatorio reciente en el sector bancario?"
    """
    
    logger.info(f"RAG query from user {current_user.get('username', 'unknown')}: {query.question[:100]}...")
    
    try:
        result = await rag_orchestrator.analyze_natural_language_query(query)
        
        logger.info(f"RAG analysis completed: {len(result.sources)} sources, {result.confidence}% confidence")
        
        return result
        
    except Exception as e:
        logger.error(f"RAG endpoint failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/nlp/examples")
async def get_nlp_examples(current_user: dict = Depends(get_current_active_user)):
    """
    ğŸ“š Example questions for natural language analysis
    """
    
    return {
        "spanish_examples": [
            "Â¿CuÃ¡les son los riesgos actuales para Banco Santander?",
            "Â¿Hay problemas regulatorios en el sector energÃ©tico?",
            "Â¿QuÃ© riesgos financieros afectan a las empresas espaÃ±olas?",
            "Â¿CuÃ¡les son los principales riesgos ESG en el sector bancario?",
            "Â¿Hay alguna investigaciÃ³n judicial reciente sobre empresas cotizadas?"
        ],
        "english_examples": [
            "What are the current risks for Banco Santander?",
            "Are there any regulatory issues in the energy sector?",
            "What financial risks affect Spanish companies?",
            "What are the main ESG concerns for banks?",
            "Are there any recent legal investigations of listed companies?"
        ],
        "tips": [
            "Be specific about the company or sector you're asking about",
            "Ask about specific risk types (financial, legal, regulatory, operational)",
            "Include time frames when relevant (e.g., 'recent risks', 'current issues')",
            "The system works best with Spanish company names and sectors"
        ]
    }

@router.get("/nlp/health")
async def rag_health_check():
    """
    ğŸ¥ Health check for RAG system dependencies
    """
    
    health_status = {
        "rag_orchestrator": "healthy",
        "vector_search_service": "unknown",
        "gemini_service": "unknown",
        "timestamp": datetime.now().isoformat()
    }
    
    try:
        # Check vector search service
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(f"{VECTOR_SEARCH_URL}/health")
            health_status["vector_search_service"] = "healthy" if response.status_code == 200 else "unhealthy"
    except:
        health_status["vector_search_service"] = "unreachable"
    
    try:
        # Check Gemini service
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(f"{GEMINI_SERVICE_URL}/health")
            health_status["gemini_service"] = "healthy" if response.status_code == 200 else "unhealthy"
    except:
        health_status["gemini_service"] = "unreachable"
    
    # Determine overall health
    if health_status["vector_search_service"] == "healthy" and health_status["gemini_service"] == "healthy":
        health_status["status"] = "healthy"
    else:
        health_status["status"] = "degraded"
    
    return health_status 